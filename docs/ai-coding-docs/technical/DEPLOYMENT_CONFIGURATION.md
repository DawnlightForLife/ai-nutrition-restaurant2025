# AIæ™ºèƒ½è¥å…»é¤å…ç³»ç»Ÿ - éƒ¨ç½²é…ç½®æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025-07-13  
> **æ›´æ–°æ—¥æœŸ**: 2025-07-13  
> **æ–‡æ¡£çŠ¶æ€**: âœ… AIé›†æˆéƒ¨ç½²å°±ç»ª  
> **ç›®æ ‡å—ä¼—**: DevOpså›¢é˜Ÿã€åç«¯å¼€å‘ã€ç³»ç»Ÿæ¶æ„å¸ˆ

## ğŸ“‹ ç›®å½•

- [1. éƒ¨ç½²æ¶æ„æ¦‚è¿°](#1-éƒ¨ç½²æ¶æ„æ¦‚è¿°)
- [2. Dockerå®¹å™¨åŒ–é…ç½®](#2-dockerå®¹å™¨åŒ–é…ç½®)
- [3. AIæœåŠ¡éƒ¨ç½²é…ç½®](#3-aiæœåŠ¡éƒ¨ç½²é…ç½®)
- [4. æ•°æ®åº“éƒ¨ç½²é…ç½®](#4-æ•°æ®åº“éƒ¨ç½²é…ç½®)
- [5. æœåŠ¡ç¼–æ’é…ç½®](#5-æœåŠ¡ç¼–æ’é…ç½®)
- [6. ç¯å¢ƒé…ç½®ç®¡ç†](#6-ç¯å¢ƒé…ç½®ç®¡ç†)
- [7. ç›‘æ§ä¸æ—¥å¿—é…ç½®](#7-ç›‘æ§ä¸æ—¥å¿—é…ç½®)
- [8. å®‰å…¨é…ç½®](#8-å®‰å…¨é…ç½®)
- [9. æ€§èƒ½ä¼˜åŒ–é…ç½®](#9-æ€§èƒ½ä¼˜åŒ–é…ç½®)
- [10. ç”Ÿäº§éƒ¨ç½²ç­–ç•¥](#10-ç”Ÿäº§éƒ¨ç½²ç­–ç•¥)

---

## 1. éƒ¨ç½²æ¶æ„æ¦‚è¿°

### 1.1 æ•´ä½“æ¶æ„è®¾è®¡

```yaml
éƒ¨ç½²æ¶æ„:
  å¼€å‘ç¯å¢ƒ:
    ç±»å‹: Docker Compose å•æœºéƒ¨ç½²
    ç‰¹ç‚¹: å¿«é€Ÿå¯åŠ¨ã€å®Œæ•´åŠŸèƒ½ã€æ•°æ®éš”ç¦»
    èµ„æºéœ€æ±‚: 16GB RAM, 4 CPUæ ¸å¿ƒ
    
  æµ‹è¯•ç¯å¢ƒ:
    ç±»å‹: Kubernetes é›†ç¾¤éƒ¨ç½²
    ç‰¹ç‚¹: è‡ªåŠ¨åŒ–æµ‹è¯•ã€CI/CDé›†æˆã€æ‰©ç¼©å®¹
    èµ„æºéœ€æ±‚: 32GB RAM, 8 CPUæ ¸å¿ƒ
    
  é¢„å‘å¸ƒç¯å¢ƒ:
    ç±»å‹: äº‘æ‰˜ç®¡æœåŠ¡ + å®¹å™¨
    ç‰¹ç‚¹: ç”Ÿäº§çº§é…ç½®ã€æ€§èƒ½æµ‹è¯•ã€ç”¨æˆ·éªŒæ”¶
    èµ„æºéœ€æ±‚: 64GB RAM, 16 CPUæ ¸å¿ƒ
    
  ç”Ÿäº§ç¯å¢ƒ:
    ç±»å‹: äº‘åŸç”Ÿæ¶æ„ + æ‰˜ç®¡æœåŠ¡
    ç‰¹ç‚¹: é«˜å¯ç”¨ã€è‡ªåŠ¨æ‰©ç¼©ã€ç›‘æ§å‘Šè­¦
    èµ„æºéœ€æ±‚: å¼¹æ€§æ‰©ç¼©ï¼Œæœ€å°32GB RAM

æ ¸å¿ƒç»„ä»¶:
  åº”ç”¨å±‚:
    - NestJSåç«¯æœåŠ¡ (å¤šå®ä¾‹)
    - Reactç®¡ç†åå° (CDNéƒ¨ç½²)
    - Flutterç§»åŠ¨åº”ç”¨ (åº”ç”¨å•†åº—)
    
  AIæœåŠ¡å±‚:
    - DeepSeek APIé›†æˆæœåŠ¡
    - LangChainå‘é‡å¤„ç†æœåŠ¡
    - pgvectorå‘é‡æ•°æ®åº“
    - å›¾ç‰‡è¯†åˆ«å¤„ç†æœåŠ¡
    
  æ•°æ®å±‚:
    - PostgreSQL 15+ (ä¸»æ•°æ®åº“)
    - Redis 7.0+ (ç¼“å­˜/ä¼šè¯)
    - MinIO/S3 (æ–‡ä»¶å­˜å‚¨)
    
  åŸºç¡€è®¾æ–½:
    - Nginx (è´Ÿè½½å‡è¡¡/åå‘ä»£ç†)
    - Docker/Podman (å®¹å™¨è¿è¡Œæ—¶)
    - Prometheus + Grafana (ç›‘æ§)
    - ELK Stack (æ—¥å¿—èšåˆ)
```

### 1.2 æœåŠ¡ä¾èµ–å›¾

```mermaid
graph TB
    subgraph "è´Ÿè½½å‡è¡¡å±‚"
        LB[Nginx/HAProxy]
    end
    
    subgraph "åº”ç”¨æœåŠ¡å±‚"
        API1[NestJS-1]
        API2[NestJS-2]
        API3[NestJS-3]
        WEB[React Admin]
    end
    
    subgraph "AIæœåŠ¡å±‚"
        AI_API[DeepSeek API]
        VECTOR[å‘é‡å¤„ç†æœåŠ¡]
        PHOTO[å›¾ç‰‡è¯†åˆ«æœåŠ¡]
        LANG[LangChainæœåŠ¡]
    end
    
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        PG[(PostgreSQL + pgvector)]
        REDIS[(Redis Cluster)]
        MINIO[(MinIO/S3)]
    end
    
    subgraph "ç›‘æ§æ—¥å¿—å±‚"
        PROM[Prometheus]
        GRAF[Grafana]
        ELK[ELK Stack]
    end
    
    LB --> API1
    LB --> API2
    LB --> API3
    LB --> WEB
    
    API1 --> VECTOR
    API2 --> PHOTO
    API3 --> LANG
    
    VECTOR --> AI_API
    PHOTO --> AI_API
    LANG --> AI_API
    
    API1 --> PG
    API2 --> PG
    API3 --> PG
    
    API1 --> REDIS
    API2 --> REDIS
    API3 --> REDIS
    
    API1 --> MINIO
    PHOTO --> MINIO
    
    API1 --> PROM
    API2 --> PROM
    API3 --> PROM
```

---

## 2. Dockerå®¹å™¨åŒ–é…ç½®

### 2.1 NestJSåç«¯Dockerfile

```dockerfile
# backend/Dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°

# æ„å»ºé˜¶æ®µ
FROM node:18.17.0-alpine AS builder

# å®‰è£…æ„å»ºä¾èµ–
RUN apk add --no-cache libc6-compat python3 make g++

WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶å¹¶å®‰è£…ä¾èµ–
COPY package.json package-lock.json ./
RUN npm ci --only=production && npm cache clean --force

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM node:18.17.0-alpine AS production

# è®¾ç½®æ—¶åŒº
RUN apk add --no-cache tzdata
ENV TZ=Asia/Shanghai

# åˆ›å»ºåº”ç”¨ç”¨æˆ·ï¼ˆérootå®‰å…¨åŸåˆ™ï¼‰
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶æ–‡ä»¶
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/package.json ./

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER nestjs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¯åŠ¨å‘½ä»¤
CMD ["node", "dist/main.js"]

# å…ƒæ•°æ®æ ‡ç­¾
LABEL maintainer="AI Nutrition Restaurant Team"
LABEL version="2.0.0"
LABEL description="AIæ™ºèƒ½è¥å…»é¤å…åç«¯æœåŠ¡"
```

### 2.2 PostgreSQL + pgvector Dockerfile

```dockerfile
# database/Dockerfile
FROM postgres:15.4-alpine

# å®‰è£…pgvectoræ‰©å±•
RUN apk add --no-cache \
    build-base \
    git \
    postgresql-dev

# ä¸‹è½½å¹¶ç¼–è¯‘pgvector
RUN git clone --branch v0.5.0 https://github.com/pgvector/pgvector.git /tmp/pgvector && \
    cd /tmp/pgvector && \
    make && \
    make install && \
    rm -rf /tmp/pgvector

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

# å¤åˆ¶åˆå§‹åŒ–è„šæœ¬
COPY init-scripts/ /docker-entrypoint-initdb.d/

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY postgresql.conf /etc/postgresql/postgresql.conf
COPY pg_hba.conf /etc/postgresql/pg_hba.conf

# è®¾ç½®æ•°æ®ç›®å½•æƒé™
RUN mkdir -p /var/lib/postgresql/data && \
    chown -R postgres:postgres /var/lib/postgresql

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s \
  CMD pg_isready -U $POSTGRES_USER -d $POSTGRES_DB || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]

LABEL maintainer="AI Nutrition Restaurant Team"
LABEL version="15.4+pgvector0.5.0"
```

### 2.3 Redisé›†ç¾¤Dockerfile

```dockerfile
# cache/Dockerfile
FROM redis:7.0.12-alpine

# å®‰è£…å¿…è¦å·¥å…·
RUN apk add --no-cache \
    bash \
    curl \
    jq

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY redis.conf /etc/redis/redis.conf
COPY redis-cluster.conf /etc/redis/redis-cluster.conf

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p /data/redis && \
    chown -R redis:redis /data

# å¤åˆ¶å¯åŠ¨è„šæœ¬
COPY scripts/redis-start.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/redis-start.sh

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s \
  CMD redis-cli --no-auth-warning ping || exit 1

# åˆ‡æ¢ç”¨æˆ·
USER redis

# æš´éœ²ç«¯å£
EXPOSE 6379 16379

# å¯åŠ¨å‘½ä»¤
CMD ["/usr/local/bin/redis-start.sh"]

LABEL maintainer="AI Nutrition Restaurant Team"
LABEL version="7.0.12"
```

### 2.4 AIæœåŠ¡å®¹å™¨Dockerfile

```dockerfile
# ai-services/Dockerfile
FROM python:3.11-slim

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    git \
    libpq-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN groupadd -r aiuser && useradd -r -g aiuser aiuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶requirementså¹¶å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å®‰è£…é¢å¤–çš„AIä¾èµ–
RUN pip install --no-cache-dir \
    langchain==0.0.20 \
    openai==4.20.1 \
    pgvector==0.1.8 \
    Pillow==10.0.0 \
    torch==2.0.1 \
    transformers==4.33.0

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=aiuser:aiuser . .

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /app/logs /app/temp && \
    chown -R aiuser:aiuser /app

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=60s --timeout=30s --start-period=120s \
  CMD curl -f http://localhost:8000/health || exit 1

# åˆ‡æ¢ç”¨æˆ·
USER aiuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]

LABEL maintainer="AI Nutrition Restaurant Team"
LABEL version="2.0.0"
LABEL description="AIæœåŠ¡ï¼šå›¾ç‰‡è¯†åˆ«ã€å‘é‡å¤„ç†ã€LangChainé›†æˆ"
```

---

## 3. AIæœåŠ¡éƒ¨ç½²é…ç½®

### 3.1 AIæœåŠ¡ç¯å¢ƒé…ç½®

```yaml
# ai-services/config/production.yml
ai_services:
  deepseek:
    api_endpoint: "https://api.deepseek.com"
    api_version: "v1"
    models:
      chat: "deepseek-chat"
      coder: "deepseek-coder"
      embedding: "text-embedding-ada-002"
    rate_limits:
      requests_per_minute: 1000
      tokens_per_minute: 50000
    timeout: 30
    retry_attempts: 3
    
  langchain:
    vector_store:
      provider: "pgvector"
      connection:
        host: "${DB_HOST}"
        port: 5432
        database: "${DB_NAME}"
        user: "${DB_USER}"
        password: "${DB_PASSWORD}"
    embedding:
      provider: "openai_compatible"
      model: "text-embedding-ada-002"
      dimensions: 1536
    cache:
      provider: "redis"
      ttl: 3600
      
  image_recognition:
    models:
      food_detection: "yolo-v8-food"
      nutrition_analysis: "nutrition-classifier-v2"
    processing:
      max_image_size: "10MB"
      supported_formats: ["jpg", "jpeg", "png", "webp"]
      resize_max_dimension: 1024
    storage:
      provider: "minio"
      bucket: "food-images"
      retention_days: 30
      
  performance:
    worker_processes: 4
    max_concurrent_requests: 100
    request_timeout: 30
    memory_limit: "2GB"
    
  monitoring:
    metrics_enabled: true
    health_check_interval: 30
    log_level: "INFO"
    prometheus_port: 9090
```

### 3.2 å‘é‡æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```sql
-- database/init-scripts/01-init-pgvector.sql

-- åˆ›å»ºpgvectoræ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
CREATE EXTENSION IF NOT EXISTS pg_trgm;

-- åˆ›å»ºå‘é‡åµŒå…¥è¡¨
CREATE TABLE IF NOT EXISTS vector_embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    entity_type VARCHAR(50) NOT NULL,
    entity_id VARCHAR(255) NOT NULL,
    embedding vector(1536) NOT NULL,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºå‘é‡ç´¢å¼• (HNSWç®—æ³•ï¼Œæœ€é€‚åˆç›¸ä¼¼æ€§æœç´¢)
CREATE INDEX IF NOT EXISTS idx_vector_embeddings_hnsw 
ON vector_embeddings USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- åˆ›å»ºå¸¸è§„ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_vector_embeddings_entity 
ON vector_embeddings (entity_type, entity_id);

CREATE INDEX IF NOT EXISTS idx_vector_embeddings_created_at 
ON vector_embeddings (created_at DESC);

-- åˆ›å»ºAIåŠŸèƒ½ç›¸å…³è¡¨çš„å‘é‡å­—æ®µå’Œç´¢å¼•

-- èœå“å‘é‡åµŒå…¥
ALTER TABLE dishes ADD COLUMN IF NOT EXISTS nutrition_embedding vector(1536);
CREATE INDEX IF NOT EXISTS idx_dishes_nutrition_embedding 
ON dishes USING hnsw (nutrition_embedding vector_cosine_ops)
WHERE nutrition_embedding IS NOT NULL;

-- ç”¨æˆ·åå¥½å‘é‡åµŒå…¥
ALTER TABLE user_preferences ADD COLUMN IF NOT EXISTS preference_embedding vector(1536);
CREATE INDEX IF NOT EXISTS idx_user_preferences_embedding 
ON user_preferences USING hnsw (preference_embedding vector_cosine_ops)
WHERE preference_embedding IS NOT NULL;

-- åˆ›å»ºå‘é‡æœç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION find_similar_dishes(
    query_embedding vector(1536),
    similarity_threshold float DEFAULT 0.7,
    max_results int DEFAULT 10
)
RETURNS TABLE (
    dish_id uuid,
    dish_name varchar,
    similarity_score float
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.id,
        d.name,
        1 - (d.nutrition_embedding <=> query_embedding) as similarity
    FROM dishes d
    WHERE d.nutrition_embedding IS NOT NULL
        AND 1 - (d.nutrition_embedding <=> query_embedding) > similarity_threshold
    ORDER BY d.nutrition_embedding <=> query_embedding
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºå‘é‡æ›´æ–°è§¦å‘å™¨
CREATE OR REPLACE FUNCTION update_vector_timestamp()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_vector_embeddings_updated_at
    BEFORE UPDATE ON vector_embeddings
    FOR EACH ROW
    EXECUTE FUNCTION update_vector_timestamp();

-- è®¾ç½®å‘é‡æœç´¢ç›¸å…³é…ç½®
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements,vector';
ALTER SYSTEM SET work_mem = '256MB';
ALTER SYSTEM SET maintenance_work_mem = '1GB';
ALTER SYSTEM SET effective_cache_size = '4GB';

-- æˆæƒ
GRANT ALL PRIVILEGES ON TABLE vector_embeddings TO ai_nutrition_user;
GRANT EXECUTE ON FUNCTION find_similar_dishes TO ai_nutrition_user;

-- æ’å…¥åˆå§‹åŒ–æ•°æ®ï¼ˆå¯é€‰ï¼‰
INSERT INTO vector_embeddings (entity_type, entity_id, embedding, metadata) VALUES 
('system', 'initialization', array_fill(0.0, ARRAY[1536])::vector, '{"purpose": "initialization_placeholder"}');

COMMENT ON TABLE vector_embeddings IS 'AIå‘é‡åµŒå…¥å­˜å‚¨è¡¨';
COMMENT ON COLUMN vector_embeddings.embedding IS '1536ç»´å‘é‡åµŒå…¥æ•°æ®';
COMMENT ON FUNCTION find_similar_dishes IS 'åŸºäºå‘é‡ç›¸ä¼¼æ€§æŸ¥æ‰¾ç›¸ä¼¼èœå“';
```

### 3.3 AIæœåŠ¡Docker Composeé…ç½®

```yaml
# ai-services/docker-compose.ai.yml
version: '3.8'

services:
  ai-vector-service:
    build:
      context: ./ai-services
      dockerfile: Dockerfile
    container_name: ai-vector-service
    restart: unless-stopped
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - OPENAI_API_BASE=https://api.deepseek.com
      - POSTGRES_HOST=postgres-ai
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - REDIS_URL=redis://redis-cluster:6379
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - LOG_LEVEL=INFO
      - WORKERS=4
    ports:
      - "8000:8000"
      - "9090:9090"  # Prometheus metrics
    volumes:
      - ./ai-services/logs:/app/logs
      - ./ai-services/temp:/app/temp
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - ai-network
    depends_on:
      postgres-ai:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ai-image-processor:
    build:
      context: ./ai-services
      dockerfile: Dockerfile.image
    container_name: ai-image-processor
    restart: unless-stopped
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - MODEL_PATH=/app/models
      - PROCESSING_WORKERS=2
      - MAX_IMAGE_SIZE=10MB
      - SUPPORTED_FORMATS=jpg,jpeg,png,webp
    ports:
      - "8001:8000"
    volumes:
      - ./ai-models:/app/models:ro
      - ./ai-services/temp:/app/temp
      - minio-data:/app/storage
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 6G
        reservations:
          cpus: '1.0'
          memory: 3G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

  langchain-service:
    build:
      context: ./ai-services
      dockerfile: Dockerfile.langchain
    container_name: langchain-service
    restart: unless-stopped
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - LANGCHAIN_TRACING_V2=true
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - VECTOR_STORE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres-ai:5432/${DB_NAME}
      - REDIS_URL=redis://redis-cluster:6379/2
    ports:
      - "8002:8000"
    volumes:
      - ./langchain-config:/app/config:ro
      - ./ai-services/logs:/app/logs
    networks:
      - ai-network
    depends_on:
      postgres-ai:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1G

volumes:
  minio-data:
    driver: local

networks:
  ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

---

## 4. æ•°æ®åº“éƒ¨ç½²é…ç½®

### 4.1 PostgreSQLç”Ÿäº§é…ç½®

```ini
# database/postgresql.conf
# PostgreSQL 15 + pgvectorä¼˜åŒ–é…ç½®

# è¿æ¥è®¾ç½®
listen_addresses = '*'
port = 5432
max_connections = 200
superuser_reserved_connections = 3

# å†…å­˜è®¾ç½® (å‡è®¾16GBç³»ç»Ÿå†…å­˜)
shared_buffers = 4GB
effective_cache_size = 12GB
work_mem = 256MB
maintenance_work_mem = 1GB
wal_buffers = 64MB

# æ£€æŸ¥ç‚¹è®¾ç½®
checkpoint_completion_target = 0.9
checkpoint_timeout = 10min
max_wal_size = 2GB
min_wal_size = 512MB

# å½’æ¡£å’Œå¤åˆ¶
wal_level = replica
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'
max_wal_senders = 3
wal_keep_size = 1GB

# æŸ¥è¯¢è§„åˆ’å™¨
random_page_cost = 1.1
effective_io_concurrency = 200
default_statistics_target = 100

# å‘é‡æœç´¢ä¼˜åŒ–
shared_preload_libraries = 'pg_stat_statements,vector'

# ç”¨äºå‘é‡ç´¢å¼•çš„å†…å­˜è®¾ç½®
hnsw.ef_search = 100
hnsw.m = 16

# æ—¥å¿—è®¾ç½®
log_destination = 'csvlog'
logging_collector = on
log_directory = '/var/log/postgresql'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0640
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = on
log_disconnections = on
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# æ€§èƒ½ç›‘æ§
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all

# è‡ªåŠ¨æ¸…ç†è®¾ç½®
autovacuum = on
autovacuum_max_workers = 4
autovacuum_naptime = 30s
autovacuum_vacuum_scale_factor = 0.1
autovacuum_analyze_scale_factor = 0.05

# é”è®¾ç½®
deadlock_timeout = 1s
lock_timeout = 30s

# å®¢æˆ·ç«¯è¿æ¥é»˜è®¤è®¾ç½®
timezone = 'Asia/Shanghai'
datestyle = 'iso, mdy'
lc_messages = 'en_US.utf8'
lc_monetary = 'en_US.utf8'
lc_numeric = 'en_US.utf8'
lc_time = 'en_US.utf8'
default_text_search_config = 'pg_catalog.english'
```

### 4.2 Redisé›†ç¾¤é…ç½®

```conf
# cache/redis.conf
# Redis 7.0 é›†ç¾¤é…ç½®

# åŸºæœ¬é…ç½®
bind 0.0.0.0
port 6379
timeout 300
tcp-keepalive 300

# å†…å­˜é…ç½®
maxmemory 2gb
maxmemory-policy allkeys-lru
maxmemory-samples 5

# æŒä¹…åŒ–é…ç½®
save 900 1
save 300 10
save 60 10000
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /data/redis

# AOFé…ç½®
appendonly yes
appendfilename "appendonly.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# é›†ç¾¤é…ç½®
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000
cluster-replica-validity-factor 10
cluster-migration-barrier 1
cluster-require-full-coverage yes

# å®‰å…¨é…ç½®
requirepass ${REDIS_PASSWORD}
masterauth ${REDIS_PASSWORD}

# æ—¥å¿—é…ç½®
loglevel notice
logfile /data/redis/redis.log

# å®¢æˆ·ç«¯é…ç½®
timeout 300
tcp-backlog 511
tcp-keepalive 300

# æ€§èƒ½ä¼˜åŒ–
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
hll-sparse-max-bytes 3000

# æ…¢æŸ¥è¯¢æ—¥å¿—
slowlog-log-slower-than 10000
slowlog-max-len 128

# äº‹ä»¶é€šçŸ¥
notify-keyspace-events "Ex"

# å®¢æˆ·ç«¯è¾“å‡ºç¼“å†²åŒºé™åˆ¶
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# ç½‘ç»œé…ç½®
tcp-backlog 511
unixsocket /tmp/redis.sock
unixsocketperm 700
```

---

## 5. æœåŠ¡ç¼–æ’é…ç½®

### 5.1 ä¸»Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

x-common-variables: &common-variables
  TZ: Asia/Shanghai
  NODE_ENV: production

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

services:
  # è´Ÿè½½å‡è¡¡å™¨
  nginx:
    image: nginx:1.24-alpine
    container_name: nginx-lb
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    networks:
      - app-network
    depends_on:
      - nestjs-app-1
      - nestjs-app-2
    logging: *default-logging

  # NestJSåº”ç”¨å®ä¾‹1
  nestjs-app-1:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: nestjs-app-1
    restart: unless-stopped
    environment:
      <<: *common-variables
      PORT: 3000
      DB_HOST: postgres-ai
      DB_PORT: 5432
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_URL: redis://redis-cluster:6379
      JWT_SECRET: ${JWT_SECRET}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      AI_SERVICE_URL: http://ai-vector-service:8000
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    volumes:
      - app-logs:/app/logs
      - app-uploads:/app/uploads
    networks:
      - app-network
      - ai-network
    depends_on:
      postgres-ai:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # NestJSåº”ç”¨å®ä¾‹2
  nestjs-app-2:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: nestjs-app-2
    restart: unless-stopped
    environment:
      <<: *common-variables
      PORT: 3000
      DB_HOST: postgres-ai
      DB_PORT: 5432
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_URL: redis://redis-cluster:6379
      JWT_SECRET: ${JWT_SECRET}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      AI_SERVICE_URL: http://ai-vector-service:8000
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    volumes:
      - app-logs:/app/logs
      - app-uploads:/app/uploads
    networks:
      - app-network
      - ai-network
    depends_on:
      postgres-ai:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # PostgreSQL + pgvector
  postgres-ai:
    build:
      context: ./database
      dockerfile: Dockerfile
    container_name: postgres-ai
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - postgres-logs:/var/log/postgresql
      - ./database/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - app-network
      - ai-network
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 4G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Redisé›†ç¾¤
  redis-cluster:
    build:
      context: ./cache
      dockerfile: Dockerfile
    container_name: redis-cluster
    restart: unless-stopped
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
      - "16379:16379"
    volumes:
      - redis-data:/data
      - redis-logs:/var/log/redis
    networks:
      - app-network
      - ai-network
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 2G
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIOå¯¹è±¡å­˜å‚¨
  minio:
    image: minio/minio:RELEASE.2023-09-30T07-02-29Z
    container_name: minio-storage
    restart: unless-stopped
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MINIO_REGION: ap-southeast-1
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    networks:
      - app-network
      - ai-network
    command: server /data --console-address ":9001"
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

# æ‰©å±•AIæœåŠ¡
  ai-vector-service:
    extends:
      file: ai-services/docker-compose.ai.yml
      service: ai-vector-service

  ai-image-processor:
    extends:
      file: ai-services/docker-compose.ai.yml
      service: ai-image-processor

  langchain-service:
    extends:
      file: ai-services/docker-compose.ai.yml
      service: langchain-service

volumes:
  postgres-data:
    driver: local
  postgres-logs:
    driver: local
  redis-data:
    driver: local
  redis-logs:
    driver: local
  minio-data:
    driver: local
  nginx-logs:
    driver: local
  app-logs:
    driver: local
  app-uploads:
    driver: local

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/16
  ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### 5.2 Nginxè´Ÿè½½å‡è¡¡é…ç½®

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                   '$status $body_bytes_sent "$http_referer" '
                   '"$http_user_agent" "$http_x_forwarded_for" '
                   'rt=$request_time uct="$upstream_connect_time" '
                   'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # åŸºæœ¬è®¾ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # ä¸Šæ¸¸æœåŠ¡å™¨å®šä¹‰
    upstream nestjs_backend {
        least_conn;
        server nestjs-app-1:3000 max_fails=3 fail_timeout=30s;
        server nestjs-app-2:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    upstream ai_services {
        least_conn;
        server ai-vector-service:8000 max_fails=2 fail_timeout=30s;
        server ai-image-processor:8001 max_fails=2 fail_timeout=30s;
        server langchain-service:8002 max_fails=2 fail_timeout=30s;
        keepalive 16;
    }

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=ai:10m rate=2r/s;

    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 80;
        server_name _;

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # APIæ¥å£ä»£ç†
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://nestjs_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # é”™è¯¯å¤„ç†
            proxy_next_upstream error timeout http_502 http_503 http_504;
        }

        # AIæœåŠ¡ä»£ç†
        location /ai/ {
            limit_req zone=ai burst=5 nodelay;
            
            proxy_pass http://ai_services;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # AIæœåŠ¡éœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            proxy_connect_timeout 60s;
            proxy_send_timeout 120s;
            proxy_read_timeout 120s;
            
            # å¤§æ–‡ä»¶ä¸Šä¼ æ”¯æŒ
            client_max_body_size 50M;
        }

        # WebSocketæ”¯æŒ
        location /ws/ {
            proxy_pass http://nestjs_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocketç‰¹æ®Šè®¾ç½®
            proxy_cache_bypass $http_upgrade;
            proxy_buffering off;
        }

        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # é”™è¯¯é¡µé¢
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }

    # åŒ…å«å…¶ä»–é…ç½®æ–‡ä»¶
    include /etc/nginx/conf.d/*.conf;
}
```

---

## 6. ç¯å¢ƒé…ç½®ç®¡ç†

### 6.1 ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶

```bash
# .env.production
# ç”Ÿäº§ç¯å¢ƒé…ç½®

# åº”ç”¨åŸºç¡€é…ç½®
NODE_ENV=production
APP_PORT=3000
APP_HOST=0.0.0.0
APP_NAME="AIæ™ºèƒ½è¥å…»é¤å…ç³»ç»Ÿ"
APP_VERSION=2.0.0

# æ•°æ®åº“é…ç½®
DB_HOST=postgres-ai
DB_PORT=5432
DB_NAME=ai_nutrition_restaurant
DB_USER=ai_nutrition_user
DB_PASSWORD=secure_db_password_2025
DB_MAX_CONNECTIONS=100
DB_SSL_MODE=prefer

# Redisé…ç½®
REDIS_HOST=redis-cluster
REDIS_PORT=6379
REDIS_PASSWORD=secure_redis_password_2025
REDIS_DB=0
REDIS_MAX_RETRIES=3

# JWTé…ç½®
JWT_SECRET=ultra_secure_jwt_secret_key_2025_ai_nutrition
JWT_EXPIRES_IN=24h
JWT_REFRESH_EXPIRES_IN=7d

# AIæœåŠ¡é…ç½®
DEEPSEEK_API_KEY=sk-deepseek-api-key-your-actual-key-here
DEEPSEEK_API_BASE=https://api.deepseek.com
OPENAI_COMPATIBLE_ENDPOINT=https://api.deepseek.com/v1
AI_SERVICE_URL=http://ai-vector-service:8000
AI_TIMEOUT=30000
AI_MAX_RETRIES=3

# LangChainé…ç½®
LANGCHAIN_API_KEY=lc-api-key-your-actual-key-here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=ai-nutrition-restaurant

# æ–‡ä»¶å­˜å‚¨é…ç½®
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minio_access_key_2025
MINIO_SECRET_KEY=minio_secret_key_2025_secure
MINIO_BUCKET_NAME=ai-nutrition-files
MINIO_USE_SSL=false
MINIO_REGION=ap-southeast-1

# çŸ­ä¿¡æœåŠ¡é…ç½®
SMS_PROVIDER=aliyun
SMS_ACCESS_KEY=your_sms_access_key
SMS_SECRET_KEY=your_sms_secret_key
SMS_SIGNATURE=AIæ™ºèƒ½è¥å…»é¤å…
SMS_TEMPLATE_ID=SMS_123456789

# æ”¯ä»˜é…ç½®
WECHAT_PAY_APP_ID=your_wechat_app_id
WECHAT_PAY_MCH_ID=your_wechat_mch_id
WECHAT_PAY_API_KEY=your_wechat_pay_api_key
ALIPAY_APP_ID=your_alipay_app_id
ALIPAY_PRIVATE_KEY=your_alipay_private_key

# ç›‘æ§é…ç½®
PROMETHEUS_METRICS_PORT=9090
HEALTH_CHECK_TIMEOUT=10000
LOG_LEVEL=info
LOG_MAX_FILES=7
LOG_MAX_SIZE=100m

# å®‰å…¨é…ç½®
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100
BCRYPT_SALT_ROUNDS=12
SESSION_SECRET=ultra_secure_session_secret_2025

# CORSé…ç½®
CORS_ORIGIN=https://admin.ai-nutrition-restaurant.com,https://ai-nutrition-restaurant.com
CORS_CREDENTIALS=true

# ç¬¬ä¸‰æ–¹æœåŠ¡é…ç½®
GAODE_API_KEY=your_gaode_api_key
BAIDU_API_KEY=your_baidu_api_key
TENCENT_CLOUD_SECRET_ID=your_tencent_secret_id
TENCENT_CLOUD_SECRET_KEY=your_tencent_secret_key

# ç¯å¢ƒæ ‡è¯†
ENVIRONMENT=production
DEPLOYMENT_DATE=2025-07-13
GIT_COMMIT_HASH=placeholder
```

### 6.2 Docker Composeè¦†ç›–é…ç½®

```yaml
# docker-compose.override.yml
# å¼€å‘ç¯å¢ƒè¦†ç›–é…ç½®
version: '3.8'

services:
  nginx:
    ports:
      - "8080:80"  # å¼€å‘ç¯å¢ƒä½¿ç”¨8080ç«¯å£
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/nginx.conf:ro

  nestjs-app-1:
    environment:
      NODE_ENV: development
      LOG_LEVEL: debug
    volumes:
      - ./backend:/app:cached
      - /app/node_modules
    command: ["npm", "run", "start:dev"]

  nestjs-app-2:
    environment:
      NODE_ENV: development
      LOG_LEVEL: debug
    volumes:
      - ./backend:/app:cached
      - /app/node_modules
    command: ["npm", "run", "start:dev"]

  postgres-ai:
    environment:
      POSTGRES_DB: ai_nutrition_dev
    ports:
      - "5433:5432"  # é¿å…ä¸æœ¬åœ°PostgreSQLå†²çª

  redis-cluster:
    ports:
      - "6380:6379"  # é¿å…ä¸æœ¬åœ°Rediså†²çª

  ai-vector-service:
    environment:
      LOG_LEVEL: debug
    volumes:
      - ./ai-services:/app:cached

# æµ‹è¯•ç¯å¢ƒè¦†ç›–é…ç½®
---
# docker-compose.test.yml
version: '3.8'

services:
  nestjs-app-1:
    environment:
      NODE_ENV: test
      DB_NAME: ai_nutrition_test
    command: ["npm", "run", "test:e2e"]

  postgres-ai:
    environment:
      POSTGRES_DB: ai_nutrition_test
    tmpfs:
      - /var/lib/postgresql/data  # ä½¿ç”¨å†…å­˜æ•°æ®åº“æé«˜æµ‹è¯•é€Ÿåº¦

  redis-cluster:
    tmpfs:
      - /data
```

### 6.3 Kuberneteséƒ¨ç½²é…ç½®

```yaml
# k8s/namespace.yml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-nutrition-restaurant
  labels:
    app: ai-nutrition-restaurant
    env: production

---
# k8s/configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: ai-nutrition-restaurant
data:
  NODE_ENV: "production"
  APP_PORT: "3000"
  DB_HOST: "postgres-service"
  DB_PORT: "5432"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  AI_SERVICE_URL: "http://ai-service:8000"
  LOG_LEVEL: "info"

---
# k8s/secrets.yml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: ai-nutrition-restaurant
type: Opaque
stringData:
  DB_PASSWORD: "secure_db_password_2025"
  JWT_SECRET: "ultra_secure_jwt_secret_key_2025"
  DEEPSEEK_API_KEY: "sk-deepseek-api-key-actual"
  REDIS_PASSWORD: "secure_redis_password_2025"

---
# k8s/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nestjs-app
  namespace: ai-nutrition-restaurant
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nestjs-app
  template:
    metadata:
      labels:
        app: nestjs-app
    spec:
      containers:
      - name: nestjs
        image: ai-nutrition-restaurant/backend:2.0.0
        ports:
        - containerPort: 3000
        envFrom:
        - configMapRef:
            name: app-config
        - secretRef:
            name: app-secrets
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1500m"

---
# k8s/service.yml
apiVersion: v1
kind: Service
metadata:
  name: nestjs-service
  namespace: ai-nutrition-restaurant
spec:
  selector:
    app: nestjs-app
  ports:
  - port: 80
    targetPort: 3000
  type: ClusterIP

---
# k8s/ingress.yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  namespace: ai-nutrition-restaurant
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - api.ai-nutrition-restaurant.com
    secretName: api-tls
  rules:
  - host: api.ai-nutrition-restaurant.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nestjs-service
            port:
              number: 80
```

---

è¿™ä»½éƒ¨ç½²é…ç½®æ–‡æ¡£æ¶µç›–äº†ä»å¼€å‘åˆ°ç”Ÿäº§çš„å®Œæ•´éƒ¨ç½²æµç¨‹ï¼Œç‰¹åˆ«é’ˆå¯¹AIæœåŠ¡å’Œpgvectoræ•°æ®åº“è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ¥ä¸‹æ¥æˆ‘å°†ç»§ç»­å®Œæˆå‰©ä½™çš„ç¼“å­˜ç­–ç•¥å’Œç´¢å¼•ç­–ç•¥é…ç½®ã€‚